<!DOCTYPE html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"><!--<![endif]-->
<head>
        <meta charset="UTF-8">
    <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
    <meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1">
    <title>RL note #4 &#8211; </title>
    <meta name="description" content="blog">
    <meta name="keywords" content="Reinforcement Learning">
    <!-- Twitter Cards -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:image" content="/assets/img/logo.png">
    <meta name="twitter:title" content="RL note #4">
    <meta name="twitter:description" content="Machine Learning">
    
    <!-- Open Graph -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="RL note #4">
    <meta property="og:description" content="Machine Learning">
    <meta property="og:url" content="/posts/RL-note-4">
    <meta property="og:site_name" content="">
    <meta property="og:image" content="/assets/img/logo.png">
    
    
    
    <link rel="canonical" href="/posts/RL-note-4">
    <link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">
    <!-- Handheld -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <!-- JS -->
    <script src="/assets/js/modernizr-3.3.1.custom.min.js"></script>
    <!-- Favicons -->
    <link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png">
    <link rel="shortcut icon" type="image/png" href="/favicon.png" />
    <link rel="shortcut icon" href="/favicon.ico" />
    <!-- Background Image -->
    
    
    
    <style type="text/css">body {background-image:url(/assets/img/placeholder-big.jpg);  background-repeat: no-repeat; background-size: cover; }</style>
    
    <!-- Post Feature Image -->
    

    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
    equationNumbers: {
      autoNumber: "AMS"
    }
},
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
  }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
  alert("Math Processing Error: "+message[1]);
});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
  alert("Math Processing Error: "+message[1]);
});
</script>
<script type="text/javascript" async
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

</head>
<body>
    	<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
		<button class="dl-trigger">Open Menu</button>
		<ul class="dl-menu">
			<li><a href="/">Home</a></li>
			<li><a href="/about/en">About</a></li>
			<li><a href="/projects">Projects</a></li>
			<li><a href="/posts/">Posts</a></li>
		</ul><!-- /.dl-menu -->
	</nav><!-- /.dl-menuwrapper -->

    <!-- Header -->
    <header class="header" role="banner">
        <div class="wrapper animated fadeIn">
            <button class="btn zoombtn" onclick="history.back()"><i class="fa fa-chevron-left"></i></button>
            <div class="content">
                <div class="page-title ">
                    <h1>RL note #4</h1>
                    <!-- <h4>22 Dec 2017</h4> -->
                    
                    <p class="reading-time">
                      <i class="fa fa-clock-o"></i>
                      

Reading time ~2 minutes

                    </p><!-- /.entry-reading-time -->
                    
                </div>
                <h1 id="강화학습">강화학습</h1>

<hr />

<h4 id="남은-문제점">남은 문제점</h4>
<ul>
  <li>계산복잡도가 높다는 문제</li>
</ul>

<hr />

<h4 id="목표">목표</h4>
<ul>
  <li>NN을 이용한 계산복잡도 문제 해결</li>
</ul>

<h2 id="그리드월드와-근사함수">그리드월드와 근사함수</h2>
<h4 id="계산복잡도가-높다는-문제">계산복잡도가 높다는 문제</h4>
<ul>
  <li>차원의 수, 노드의 수가 많아지면 Q함수를 가지고 있기 너무 큼</li>
  <li>10 * 10 그리드월드라 할 때 행동이 4가지이기 때문에 10 * 10 * 4의 Q함수 테이블을 연산에 이용해야 함</li>
  <li>근사함수를 통한 가치함수의 매개변수화를 통해 해결가능</li>
  <li>SARSA -&gt; 딥살사</li>
  <li>몬테카를로 -&gt; 폴리시 그레이디언트</li>
  <li>Q-learning -&gt; DQN(Deep Q-network)</li>
</ul>

<h4 id="인공신경망nn과-케라스">인공신경망(NN)과 케라스</h4>
<ul>
  <li>인공신경망에 대한 설명은 생락</li>
  <li>케라스에서 인공신경망 구현 코드</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
  <span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">y_train</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'RMSProp'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mse'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'RMSProp'</span><span class="p">)</span>

  <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code></pre></figure>

<h4 id="딥살사-이론">딥살사 이론</h4>
<ul>
  <li>개요
    <ul>
      <li>살사 + DNN</li>
      <li>살사이론의 q함수 테이블을 근사함수를 만들어 저장</li>
      <li>행동시 지정 위치의 q함수들만 예측</li>
      <li>개선은 다음 지점의 q함수를 정답으로 하여 인공신경망 개선교육</li>
    </ul>
  </li>
  <li>심층신경망
    <ul>
      <li>현재 상태에 대한 Q함수 예측</li>
      <li>입력 : 현재 상태에 대한 정보</li>
      <li>심층신경망(입력층1, 은닉층2, 출력층1:linear)</li>
      <li>출력 : q함수 테이블</li>
    </ul>
  </li>
  <li>행동
    <ul>
      <li>현재 상태(s)를 입력으로 심층신경망을 통하여 q함수 테이블을 생성</li>
      <li>q함수 테이블에서 최고값으로 행동으로 선택(a)</li>
    </ul>
  </li>
  <li>개선
    <ul>
      <li>심층신경망의 가중치를 개선 ( = Q함수 개선 )</li>
      <li>살사에서의 오류값을 이용</li>
      <li>오차 = (정답 – 예측)</li>
      <li>오차 = R + γQ(S2, A2) – Q(S1, S2)</li>
    </ul>
  </li>
</ul>

<p class="notice">정책기반 강화학습 vs 가치기반 강화학습<br />
정책기반 : 정책에 따라 행동(정책평가가 이루어지지 않으면 최고가치가 존재해도 따라가지 않음)<br />
가치기반 : 최고가치가 최고정책으라는 가정하에 행동</p>

<h4 id="폴리시-그레이디언트">폴리시 그레이디언트</h4>
<ul>
  <li>개요
    <ul>
      <li>몬테카를로 + DNN</li>
      <li>행동 -&gt; 행동 -&gt; 행동 -&gt; … -&gt; 개선</li>
      <li>q함수 근사가 아닌 정책 근사로 행동 및 개선</li>
      <li>탐욕정책이 아닌 각 방향으로 갈 확률 근사</li>
    </ul>
  </li>
  <li>심층신경망
    <ul>
      <li>현재 상태에 대한 각 방향의 정책 예측</li>
      <li>입력 : 현재 상태에 대한 정보</li>
      <li>심층신경망(입력층1, 은닉층2, 출력층1:sofrmax)</li>
      <li>출력 : 각 행동을 할 확률</li>
    </ul>
  </li>
  <li>행동
    <ul>
      <li>현재 상태(s)를 입력으로 심층신경망을 통하여 각 방향으로 갈 확률 계산</li>
      <li>확률 기반으로 하나 선택(룰렛휠)</li>
      <li>끝날 때까지 계속 이동</li>
    </ul>
  </li>
  <li>개선
    <ul>
      <li>지나온 경로 각각의 cost 계산</li>
      <li>s 입력, cost로 개선</li>
    </ul>
  </li>
</ul>

<p class="notice">문제<br />
현재 정책에 대한 정답값이 없음<br />
cost의 계산이 불가<br /><br />
해결책<br />
각 위치의 가치함수(감가율이 계산된 보상값들의 합) = A<br />
각 위치에서의 행동에 해당하는 정책값 = B<br />
cost = - log(B) * A<br /><br />
왜냐하면…<br />
정책신경망 업데이트 방식 : Q = Q + 학습속도*(cost)’<br />
cost = 정책 * q함수 (Richard Sutton의 논문)<br />
cost’ = 정책’ * q함수<br />
cost’ = (정책’/정책) * 가치함수 =&gt;  because. 가치함수 = 정책 ** q함수 (기존식)<br />
cost’ = (log(정책))’ * 가치함수<br />
cost’ = (log(정책))’ * (감가율이 계산된 보상의 합)</p>
<p><code class="language-plaintext highlighter-rouge">계산복잡도 문제 해결</code></p>

                <div class="entry-meta">
                <br>
<hr>

<div style="width:100%">
<div style="width:10%;float:left;">
    <span style="color:#999999;">출처</span>
</div>
<div style="width:90%;float:left;">

    <span style="color:#999999;">이웅원 외 4명 저 '파이썬과 케라스로 배우는 강화학습'</span><br>

</div>
<span style="color:black;"></span>
<span class="refer-tags">
</span>
</div>

<span class="entry-tags"><a href="/tags/#Reinforcement Learning" title="Pages tagged Reinforcement Learning" class="tag"><span class="term">Reinforcement Learning</span></a></span>
<div style="clear:both"></div>

                </div>
            </div>
        </div>
        <!-- <section id="disqus_thread" class="animated fadeInUp"></section><!-- /#disqus_thread --> -->
    </header>
        <!-- JS -->
    <script src="/assets/js/jquery-1.12.0.min.js"></script>
    <script src="/assets/js/jquery.dlmenu.min.js"></script>
    <script src="/assets/js/jquery.goup.min.js"></script>
    <script src="/assets/js/jquery.magnific-popup.min.js"></script>
    <script src="/assets/js/jquery.fitvid.min.js"></script>
    <script src="/assets/js/scripts.js"></script>
    
    
    <!-- MathJax -->
    <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
</body>
</html>
